{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 神经网络模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk_c2_s0.1_b16_lr0.001_d0.5_e100_up\n",
      "models/model_sk_c2_s0.1_b16_lr0.001_d0.5_e100_up.pth\n",
      "True\n",
      "1\n",
      "GeForce MX150\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class Para:\n",
    "    # tensor_board_log_dir = 'runs/exp0'\n",
    "    feature_column_start_name = 'ep_ratio_ttm'\n",
    "    feature_column_end_name = 'BR'\n",
    "\n",
    "    # 模型设置\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    classification = 2 # 2, 3\n",
    "\n",
    "    # 权重\n",
    "    cross_weight = list()\n",
    "    if classification == 3:\n",
    "        cross_weight = [1.0, 1.0 ,1.0]\n",
    "    elif classification == 2:\n",
    "        cross_weight = [1.0, 1.0]\n",
    "    elif classification == 5:\n",
    "        cross_weight = [1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "\n",
    "    batch_size = 16\n",
    "    lr = 1e-3\n",
    "    drop = 0.5\n",
    "    epochs = 100\n",
    "\n",
    "    # 数据集设置\n",
    "    month_in_sample = range(0, 1)\n",
    "    # month_test = range(36, 48)\n",
    "\n",
    "    percent_cv = 0.1 # 10% cross validation\n",
    "\n",
    "    data_path = 'data/sk_space_1d_rate_20d_up_train'\n",
    "\n",
    "\n",
    "    seed = 2022\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    info_str0 = data_path[5:7]+'_'+'c'+str(classification)+'_s'+str(percent_cv)\n",
    "    info_str1 = '_b'+str(batch_size)+'_lr'+str(lr)+'_d'+str(drop)+'_e'+str(epochs)\n",
    "    info_str = info_str0 + info_str1 + '_up'\n",
    "\n",
    "    save_model_path = 'models/'+'model_'+info_str+'.pth'\n",
    "\n",
    "para = Para()\n",
    "print(para.info_str)\n",
    "print(para.save_model_path)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 构建训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     return_bin order_book_id board_type sector_code  month        date  \\\n0           0.0   600376.XSHG  MainBoard  RealEstate      0  2014-09-01   \n1           0.0   600376.XSHG  MainBoard  RealEstate      1  2014-09-02   \n2           0.0   600376.XSHG  MainBoard  RealEstate      2  2014-09-03   \n3           0.0   600376.XSHG  MainBoard  RealEstate      3  2014-09-04   \n4           0.0   600376.XSHG  MainBoard  RealEstate      4  2014-09-05   \n..          ...           ...        ...         ...    ...         ...   \n507         1.0   600376.XSHG  MainBoard  RealEstate    522  2019-03-26   \n508         1.0   600376.XSHG  MainBoard  RealEstate    523  2019-03-27   \n509         1.0   600376.XSHG  MainBoard  RealEstate    524  2019-03-28   \n510         1.0   600376.XSHG  MainBoard  RealEstate    525  2019-03-29   \n511         1.0   600376.XSHG  MainBoard  RealEstate    526  2019-04-01   \n\n     yield_rate  ep_ratio_ttm  pb_ratio_ttm  sp_ratio_ttm  ...     RSI10  \\\n0      0.155301      1.389569     -0.742512      1.004896  ... -0.723738   \n1      0.199428      1.357446     -0.724225      0.971029  ... -0.103967   \n2      0.046038      1.319701     -0.702279      0.931236  ...  0.421506   \n3      0.314559      1.282805     -0.680334      0.892337  ...  0.368239   \n4      0.495197      1.295012     -0.687649      0.905206  ...  0.155170   \n..          ...           ...           ...           ...  ...       ...   \n507   -0.447526      1.101898     -0.840072      1.256462  ...  1.215658   \n508   -0.664240      1.108614     -0.843992      1.264758  ...  0.163493   \n509   -0.429381      1.195120     -0.892992      1.371614  ... -1.154517   \n510   -1.031287      0.973481     -0.761673      1.097834  ...  0.088586   \n511   -1.011609      0.922105     -0.728354      1.034371  ... -0.004968   \n\n           SY    BIAS20     VOL30     VOL60    VOL120    VOLT20    VOLT60  \\\n0   -0.340049 -0.606578 -0.066340 -0.210841  0.083270 -1.045114 -0.393679   \n1    0.426934 -0.429731 -0.086189 -0.211403  0.066068 -1.074718 -0.392116   \n2    0.426934 -0.246464 -0.087480 -0.202554  0.054438 -1.073104 -0.389364   \n3    0.426934 -0.082092 -0.157214 -0.193872  0.052077 -1.054760 -0.387450   \n4    0.426934 -0.160803 -0.182925 -0.189293  0.048252 -1.045388 -0.387953   \n..        ...       ...       ...       ...       ...       ...       ...   \n507 -1.107033  0.357106 -0.575565 -0.695986 -0.803012  1.098151  0.541113   \n508 -1.874017  0.212989 -0.579929 -0.694342 -0.802500  1.036168  0.577849   \n509 -2.641001 -0.324107 -0.578545 -0.692693 -0.801382  0.942849  0.593940   \n510 -2.641001  0.752425 -0.569861 -0.686683 -0.798262  0.916414  0.647282   \n511 -1.874017  0.910051 -0.557743 -0.679731 -0.793508  0.922264  0.711278   \n\n           AR        BR  \n0   -0.872230 -0.719400  \n1   -0.807516 -0.830423  \n2   -0.601557 -0.647419  \n3   -0.132819 -0.188955  \n4   -0.451531 -0.477728  \n..        ...       ...  \n507  1.196026  2.311781  \n508  0.955672  2.051009  \n509  0.750872  1.797271  \n510  1.503490  2.550063  \n511  1.893160  2.908374  \n\n[512 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>return_bin</th>\n      <th>order_book_id</th>\n      <th>board_type</th>\n      <th>sector_code</th>\n      <th>month</th>\n      <th>date</th>\n      <th>yield_rate</th>\n      <th>ep_ratio_ttm</th>\n      <th>pb_ratio_ttm</th>\n      <th>sp_ratio_ttm</th>\n      <th>...</th>\n      <th>RSI10</th>\n      <th>SY</th>\n      <th>BIAS20</th>\n      <th>VOL30</th>\n      <th>VOL60</th>\n      <th>VOL120</th>\n      <th>VOLT20</th>\n      <th>VOLT60</th>\n      <th>AR</th>\n      <th>BR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>600376.XSHG</td>\n      <td>MainBoard</td>\n      <td>RealEstate</td>\n      <td>0</td>\n      <td>2014-09-01</td>\n      <td>0.155301</td>\n      <td>1.389569</td>\n      <td>-0.742512</td>\n      <td>1.004896</td>\n      <td>...</td>\n      <td>-0.723738</td>\n      <td>-0.340049</td>\n      <td>-0.606578</td>\n      <td>-0.066340</td>\n      <td>-0.210841</td>\n      <td>0.083270</td>\n      <td>-1.045114</td>\n      <td>-0.393679</td>\n      <td>-0.872230</td>\n      <td>-0.719400</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>600376.XSHG</td>\n      <td>MainBoard</td>\n      <td>RealEstate</td>\n      <td>1</td>\n      <td>2014-09-02</td>\n      <td>0.199428</td>\n      <td>1.357446</td>\n      <td>-0.724225</td>\n      <td>0.971029</td>\n      <td>...</td>\n      <td>-0.103967</td>\n      <td>0.426934</td>\n      <td>-0.429731</td>\n      <td>-0.086189</td>\n      <td>-0.211403</td>\n      <td>0.066068</td>\n      <td>-1.074718</td>\n      <td>-0.392116</td>\n      <td>-0.807516</td>\n      <td>-0.830423</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>600376.XSHG</td>\n      <td>MainBoard</td>\n      <td>RealEstate</td>\n      <td>2</td>\n      <td>2014-09-03</td>\n      <td>0.046038</td>\n      <td>1.319701</td>\n      <td>-0.702279</td>\n      <td>0.931236</td>\n      <td>...</td>\n      <td>0.421506</td>\n      <td>0.426934</td>\n      <td>-0.246464</td>\n      <td>-0.087480</td>\n      <td>-0.202554</td>\n      <td>0.054438</td>\n      <td>-1.073104</td>\n      <td>-0.389364</td>\n      <td>-0.601557</td>\n      <td>-0.647419</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>600376.XSHG</td>\n      <td>MainBoard</td>\n      <td>RealEstate</td>\n      <td>3</td>\n      <td>2014-09-04</td>\n      <td>0.314559</td>\n      <td>1.282805</td>\n      <td>-0.680334</td>\n      <td>0.892337</td>\n      <td>...</td>\n      <td>0.368239</td>\n      <td>0.426934</td>\n      <td>-0.082092</td>\n      <td>-0.157214</td>\n      <td>-0.193872</td>\n      <td>0.052077</td>\n      <td>-1.054760</td>\n      <td>-0.387450</td>\n      <td>-0.132819</td>\n      <td>-0.188955</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>600376.XSHG</td>\n      <td>MainBoard</td>\n      <td>RealEstate</td>\n      <td>4</td>\n      <td>2014-09-05</td>\n      <td>0.495197</td>\n      <td>1.295012</td>\n      <td>-0.687649</td>\n      <td>0.905206</td>\n      <td>...</td>\n      <td>0.155170</td>\n      <td>0.426934</td>\n      <td>-0.160803</td>\n      <td>-0.182925</td>\n      <td>-0.189293</td>\n      <td>0.048252</td>\n      <td>-1.045388</td>\n      <td>-0.387953</td>\n      <td>-0.451531</td>\n      <td>-0.477728</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>507</th>\n      <td>1.0</td>\n      <td>600376.XSHG</td>\n      <td>MainBoard</td>\n      <td>RealEstate</td>\n      <td>522</td>\n      <td>2019-03-26</td>\n      <td>-0.447526</td>\n      <td>1.101898</td>\n      <td>-0.840072</td>\n      <td>1.256462</td>\n      <td>...</td>\n      <td>1.215658</td>\n      <td>-1.107033</td>\n      <td>0.357106</td>\n      <td>-0.575565</td>\n      <td>-0.695986</td>\n      <td>-0.803012</td>\n      <td>1.098151</td>\n      <td>0.541113</td>\n      <td>1.196026</td>\n      <td>2.311781</td>\n    </tr>\n    <tr>\n      <th>508</th>\n      <td>1.0</td>\n      <td>600376.XSHG</td>\n      <td>MainBoard</td>\n      <td>RealEstate</td>\n      <td>523</td>\n      <td>2019-03-27</td>\n      <td>-0.664240</td>\n      <td>1.108614</td>\n      <td>-0.843992</td>\n      <td>1.264758</td>\n      <td>...</td>\n      <td>0.163493</td>\n      <td>-1.874017</td>\n      <td>0.212989</td>\n      <td>-0.579929</td>\n      <td>-0.694342</td>\n      <td>-0.802500</td>\n      <td>1.036168</td>\n      <td>0.577849</td>\n      <td>0.955672</td>\n      <td>2.051009</td>\n    </tr>\n    <tr>\n      <th>509</th>\n      <td>1.0</td>\n      <td>600376.XSHG</td>\n      <td>MainBoard</td>\n      <td>RealEstate</td>\n      <td>524</td>\n      <td>2019-03-28</td>\n      <td>-0.429381</td>\n      <td>1.195120</td>\n      <td>-0.892992</td>\n      <td>1.371614</td>\n      <td>...</td>\n      <td>-1.154517</td>\n      <td>-2.641001</td>\n      <td>-0.324107</td>\n      <td>-0.578545</td>\n      <td>-0.692693</td>\n      <td>-0.801382</td>\n      <td>0.942849</td>\n      <td>0.593940</td>\n      <td>0.750872</td>\n      <td>1.797271</td>\n    </tr>\n    <tr>\n      <th>510</th>\n      <td>1.0</td>\n      <td>600376.XSHG</td>\n      <td>MainBoard</td>\n      <td>RealEstate</td>\n      <td>525</td>\n      <td>2019-03-29</td>\n      <td>-1.031287</td>\n      <td>0.973481</td>\n      <td>-0.761673</td>\n      <td>1.097834</td>\n      <td>...</td>\n      <td>0.088586</td>\n      <td>-2.641001</td>\n      <td>0.752425</td>\n      <td>-0.569861</td>\n      <td>-0.686683</td>\n      <td>-0.798262</td>\n      <td>0.916414</td>\n      <td>0.647282</td>\n      <td>1.503490</td>\n      <td>2.550063</td>\n    </tr>\n    <tr>\n      <th>511</th>\n      <td>1.0</td>\n      <td>600376.XSHG</td>\n      <td>MainBoard</td>\n      <td>RealEstate</td>\n      <td>526</td>\n      <td>2019-04-01</td>\n      <td>-1.011609</td>\n      <td>0.922105</td>\n      <td>-0.728354</td>\n      <td>1.034371</td>\n      <td>...</td>\n      <td>-0.004968</td>\n      <td>-1.874017</td>\n      <td>0.910051</td>\n      <td>-0.557743</td>\n      <td>-0.679731</td>\n      <td>-0.793508</td>\n      <td>0.922264</td>\n      <td>0.711278</td>\n      <td>1.893160</td>\n      <td>2.908374</td>\n    </tr>\n  </tbody>\n</table>\n<p>512 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_in_sample = None\n",
    "for i_month in para.month_in_sample:\n",
    "    file_name = para.data_path + '/' + str(i_month) + '.csv'\n",
    "    data_curr_month = pd.read_csv(file_name)\n",
    "\n",
    "    data_curr_month = data_curr_month.dropna(axis=0)\n",
    "\n",
    "    data_curr_month.insert(loc=0, column='return_bin', value=np.nan)\n",
    "\n",
    "    data_curr_month.loc[data_curr_month['yield_rate']>0, 'return_bin'] = 0\n",
    "    data_curr_month.loc[data_curr_month['yield_rate']<=0, 'return_bin'] = 1\n",
    "\n",
    "    if i_month == para.month_in_sample[0]:\n",
    "        data_in_sample = data_curr_month\n",
    "    else:\n",
    "        data_in_sample = pd.concat([data_in_sample, data_curr_month])\n",
    "        # data_in_sample = data_in_sample.append(data_curr_month)\n",
    "\n",
    "data_in_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     ep_ratio_ttm  pb_ratio_ttm  sp_ratio_ttm  MACD_DIFF  MACD_DEA  MACD_HIST  \\\n79       0.310367      0.438979     -0.294945   0.751335  0.864112  -0.125413   \n382     -0.961220     -0.413666     -0.442000  -0.546780 -0.615578   0.016755   \n198     -0.704593      0.097075     -0.533676  -0.507531 -0.097829  -1.716827   \n417     -0.625312     -0.548998     -0.393653  -0.890804 -0.890359  -0.374639   \n493      1.407756     -1.002750      1.634275   0.381003  0.177336   0.882659   \n..            ...           ...           ...        ...       ...        ...   \n177     -0.813878      3.291659     -1.310116   3.360619  2.969722   2.764531   \n112     -0.026166      0.972536     -0.625767  -0.205537  0.219807  -1.652657   \n173     -0.716752      2.830277     -1.207039   2.320741  2.284990   1.048269   \n220     -0.656152     -0.004056     -0.456864  -0.971758 -1.054307  -0.103754   \n381     -0.951318     -0.435371     -0.421375  -0.589330 -0.625773  -0.118633   \n\n        RSI10        SY    BIAS20     VOL30     VOL60    VOL120    VOLT20  \\\n79   1.024170  0.426934  1.671853  1.382365  0.886554  0.667063 -0.097866   \n382 -0.026086  0.426934 -0.261236 -0.781431 -0.793854 -0.531507 -1.008564   \n198 -1.755353 -0.340049 -1.113178 -0.382990 -0.441483 -0.384283  0.392090   \n417 -1.877524 -1.107033 -0.798939 -0.824048 -0.826394 -0.825700 -0.704042   \n493  1.772208  2.727886  0.950798 -0.727155 -0.778790 -0.864582  0.129387   \n..        ...       ...       ...       ...       ...       ...       ...   \n177  0.978601  0.426934  2.042504  2.269002  2.231730  2.679046  3.030261   \n112 -0.571046 -1.107033 -0.859580  1.577855  2.007490  1.362873  0.801238   \n173  1.315469  0.426934  1.625157  2.138479  2.075666  2.650899  1.916798   \n220 -0.836701 -0.340049 -0.495085 -0.715596 -0.553193 -0.437514 -0.795005   \n381 -0.674102 -0.340049 -0.416496 -0.788625 -0.794964 -0.531353 -1.019610   \n\n       VOLT60        AR        BR  \n79   0.581123  0.629129  0.987442  \n382 -0.947869 -0.664390 -0.409365  \n198 -0.222195  2.283511  0.601296  \n417 -0.832161 -1.224591 -0.942376  \n493 -0.414433  0.861440  1.890209  \n..        ...       ...       ...  \n177  3.072342  0.278871  1.060516  \n112  1.849816  0.417637 -0.246091  \n173  2.410884  0.046822  0.869918  \n220 -0.175838 -1.247266 -1.362879  \n381 -0.947760 -1.240359 -0.890810  \n\n[460 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ep_ratio_ttm</th>\n      <th>pb_ratio_ttm</th>\n      <th>sp_ratio_ttm</th>\n      <th>MACD_DIFF</th>\n      <th>MACD_DEA</th>\n      <th>MACD_HIST</th>\n      <th>RSI10</th>\n      <th>SY</th>\n      <th>BIAS20</th>\n      <th>VOL30</th>\n      <th>VOL60</th>\n      <th>VOL120</th>\n      <th>VOLT20</th>\n      <th>VOLT60</th>\n      <th>AR</th>\n      <th>BR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>79</th>\n      <td>0.310367</td>\n      <td>0.438979</td>\n      <td>-0.294945</td>\n      <td>0.751335</td>\n      <td>0.864112</td>\n      <td>-0.125413</td>\n      <td>1.024170</td>\n      <td>0.426934</td>\n      <td>1.671853</td>\n      <td>1.382365</td>\n      <td>0.886554</td>\n      <td>0.667063</td>\n      <td>-0.097866</td>\n      <td>0.581123</td>\n      <td>0.629129</td>\n      <td>0.987442</td>\n    </tr>\n    <tr>\n      <th>382</th>\n      <td>-0.961220</td>\n      <td>-0.413666</td>\n      <td>-0.442000</td>\n      <td>-0.546780</td>\n      <td>-0.615578</td>\n      <td>0.016755</td>\n      <td>-0.026086</td>\n      <td>0.426934</td>\n      <td>-0.261236</td>\n      <td>-0.781431</td>\n      <td>-0.793854</td>\n      <td>-0.531507</td>\n      <td>-1.008564</td>\n      <td>-0.947869</td>\n      <td>-0.664390</td>\n      <td>-0.409365</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>-0.704593</td>\n      <td>0.097075</td>\n      <td>-0.533676</td>\n      <td>-0.507531</td>\n      <td>-0.097829</td>\n      <td>-1.716827</td>\n      <td>-1.755353</td>\n      <td>-0.340049</td>\n      <td>-1.113178</td>\n      <td>-0.382990</td>\n      <td>-0.441483</td>\n      <td>-0.384283</td>\n      <td>0.392090</td>\n      <td>-0.222195</td>\n      <td>2.283511</td>\n      <td>0.601296</td>\n    </tr>\n    <tr>\n      <th>417</th>\n      <td>-0.625312</td>\n      <td>-0.548998</td>\n      <td>-0.393653</td>\n      <td>-0.890804</td>\n      <td>-0.890359</td>\n      <td>-0.374639</td>\n      <td>-1.877524</td>\n      <td>-1.107033</td>\n      <td>-0.798939</td>\n      <td>-0.824048</td>\n      <td>-0.826394</td>\n      <td>-0.825700</td>\n      <td>-0.704042</td>\n      <td>-0.832161</td>\n      <td>-1.224591</td>\n      <td>-0.942376</td>\n    </tr>\n    <tr>\n      <th>493</th>\n      <td>1.407756</td>\n      <td>-1.002750</td>\n      <td>1.634275</td>\n      <td>0.381003</td>\n      <td>0.177336</td>\n      <td>0.882659</td>\n      <td>1.772208</td>\n      <td>2.727886</td>\n      <td>0.950798</td>\n      <td>-0.727155</td>\n      <td>-0.778790</td>\n      <td>-0.864582</td>\n      <td>0.129387</td>\n      <td>-0.414433</td>\n      <td>0.861440</td>\n      <td>1.890209</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>177</th>\n      <td>-0.813878</td>\n      <td>3.291659</td>\n      <td>-1.310116</td>\n      <td>3.360619</td>\n      <td>2.969722</td>\n      <td>2.764531</td>\n      <td>0.978601</td>\n      <td>0.426934</td>\n      <td>2.042504</td>\n      <td>2.269002</td>\n      <td>2.231730</td>\n      <td>2.679046</td>\n      <td>3.030261</td>\n      <td>3.072342</td>\n      <td>0.278871</td>\n      <td>1.060516</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>-0.026166</td>\n      <td>0.972536</td>\n      <td>-0.625767</td>\n      <td>-0.205537</td>\n      <td>0.219807</td>\n      <td>-1.652657</td>\n      <td>-0.571046</td>\n      <td>-1.107033</td>\n      <td>-0.859580</td>\n      <td>1.577855</td>\n      <td>2.007490</td>\n      <td>1.362873</td>\n      <td>0.801238</td>\n      <td>1.849816</td>\n      <td>0.417637</td>\n      <td>-0.246091</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>-0.716752</td>\n      <td>2.830277</td>\n      <td>-1.207039</td>\n      <td>2.320741</td>\n      <td>2.284990</td>\n      <td>1.048269</td>\n      <td>1.315469</td>\n      <td>0.426934</td>\n      <td>1.625157</td>\n      <td>2.138479</td>\n      <td>2.075666</td>\n      <td>2.650899</td>\n      <td>1.916798</td>\n      <td>2.410884</td>\n      <td>0.046822</td>\n      <td>0.869918</td>\n    </tr>\n    <tr>\n      <th>220</th>\n      <td>-0.656152</td>\n      <td>-0.004056</td>\n      <td>-0.456864</td>\n      <td>-0.971758</td>\n      <td>-1.054307</td>\n      <td>-0.103754</td>\n      <td>-0.836701</td>\n      <td>-0.340049</td>\n      <td>-0.495085</td>\n      <td>-0.715596</td>\n      <td>-0.553193</td>\n      <td>-0.437514</td>\n      <td>-0.795005</td>\n      <td>-0.175838</td>\n      <td>-1.247266</td>\n      <td>-1.362879</td>\n    </tr>\n    <tr>\n      <th>381</th>\n      <td>-0.951318</td>\n      <td>-0.435371</td>\n      <td>-0.421375</td>\n      <td>-0.589330</td>\n      <td>-0.625773</td>\n      <td>-0.118633</td>\n      <td>-0.674102</td>\n      <td>-0.340049</td>\n      <td>-0.416496</td>\n      <td>-0.788625</td>\n      <td>-0.794964</td>\n      <td>-0.531353</td>\n      <td>-1.019610</td>\n      <td>-0.947760</td>\n      <td>-1.240359</td>\n      <td>-0.890810</td>\n    </tr>\n  </tbody>\n</table>\n<p>460 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_in_sample = data_in_sample.loc[:, para.feature_column_start_name: para.feature_column_end_name]\n",
    "y_in_sample = data_in_sample.loc[:, 'return_bin']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X_in_sample, y_in_sample, test_size=para.percent_cv, shuffle=True, random_state=para.seed)\n",
    "# X_train, X_cv, y_train, y_cv = train_test_split(X_in_sample, y_in_sample, test_size=para.percent_cv, shuffle=False)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "79     0.0\n382    1.0\n198    1.0\n417    1.0\n493    0.0\n      ... \n177    1.0\n112    0.0\n173    1.0\n220    0.0\n381    1.0\nName: return_bin, Length: 460, dtype: float64"
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     ep_ratio_ttm  pb_ratio_ttm  sp_ratio_ttm  MACD_DIFF  MACD_DEA  MACD_HIST  \\\n79       0.310367      0.438979     -0.294945   0.751335  0.864112  -0.125413   \n382     -0.961220     -0.413666     -0.442000  -0.546780 -0.615578   0.016755   \n198     -0.704593      0.097075     -0.533676  -0.507531 -0.097829  -1.716827   \n417     -0.625312     -0.548998     -0.393653  -0.890804 -0.890359  -0.374639   \n493      1.407756     -1.002750      1.634275   0.381003  0.177336   0.882659   \n..            ...           ...           ...        ...       ...        ...   \n177     -0.813878      3.291659     -1.310116   3.360619  2.969722   2.764531   \n112     -0.026166      0.972536     -0.625767  -0.205537  0.219807  -1.652657   \n173     -0.716752      2.830277     -1.207039   2.320741  2.284990   1.048269   \n220     -0.656152     -0.004056     -0.456864  -0.971758 -1.054307  -0.103754   \n381     -0.951318     -0.435371     -0.421375  -0.589330 -0.625773  -0.118633   \n\n        RSI10        SY    BIAS20     VOL30     VOL60    VOL120    VOLT20  \\\n79   1.024170  0.426934  1.671853  1.382365  0.886554  0.667063 -0.097866   \n382 -0.026086  0.426934 -0.261236 -0.781431 -0.793854 -0.531507 -1.008564   \n198 -1.755353 -0.340049 -1.113178 -0.382990 -0.441483 -0.384283  0.392090   \n417 -1.877524 -1.107033 -0.798939 -0.824048 -0.826394 -0.825700 -0.704042   \n493  1.772208  2.727886  0.950798 -0.727155 -0.778790 -0.864582  0.129387   \n..        ...       ...       ...       ...       ...       ...       ...   \n177  0.978601  0.426934  2.042504  2.269002  2.231730  2.679046  3.030261   \n112 -0.571046 -1.107033 -0.859580  1.577855  2.007490  1.362873  0.801238   \n173  1.315469  0.426934  1.625157  2.138479  2.075666  2.650899  1.916798   \n220 -0.836701 -0.340049 -0.495085 -0.715596 -0.553193 -0.437514 -0.795005   \n381 -0.674102 -0.340049 -0.416496 -0.788625 -0.794964 -0.531353 -1.019610   \n\n       VOLT60        AR        BR  return_bin  \n79   0.581123  0.629129  0.987442         0.0  \n382 -0.947869 -0.664390 -0.409365         1.0  \n198 -0.222195  2.283511  0.601296         1.0  \n417 -0.832161 -1.224591 -0.942376         1.0  \n493 -0.414433  0.861440  1.890209         0.0  \n..        ...       ...       ...         ...  \n177  3.072342  0.278871  1.060516         1.0  \n112  1.849816  0.417637 -0.246091         0.0  \n173  2.410884  0.046822  0.869918         1.0  \n220 -0.175838 -1.247266 -1.362879         0.0  \n381 -0.947760 -1.240359 -0.890810         1.0  \n\n[460 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ep_ratio_ttm</th>\n      <th>pb_ratio_ttm</th>\n      <th>sp_ratio_ttm</th>\n      <th>MACD_DIFF</th>\n      <th>MACD_DEA</th>\n      <th>MACD_HIST</th>\n      <th>RSI10</th>\n      <th>SY</th>\n      <th>BIAS20</th>\n      <th>VOL30</th>\n      <th>VOL60</th>\n      <th>VOL120</th>\n      <th>VOLT20</th>\n      <th>VOLT60</th>\n      <th>AR</th>\n      <th>BR</th>\n      <th>return_bin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>79</th>\n      <td>0.310367</td>\n      <td>0.438979</td>\n      <td>-0.294945</td>\n      <td>0.751335</td>\n      <td>0.864112</td>\n      <td>-0.125413</td>\n      <td>1.024170</td>\n      <td>0.426934</td>\n      <td>1.671853</td>\n      <td>1.382365</td>\n      <td>0.886554</td>\n      <td>0.667063</td>\n      <td>-0.097866</td>\n      <td>0.581123</td>\n      <td>0.629129</td>\n      <td>0.987442</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>382</th>\n      <td>-0.961220</td>\n      <td>-0.413666</td>\n      <td>-0.442000</td>\n      <td>-0.546780</td>\n      <td>-0.615578</td>\n      <td>0.016755</td>\n      <td>-0.026086</td>\n      <td>0.426934</td>\n      <td>-0.261236</td>\n      <td>-0.781431</td>\n      <td>-0.793854</td>\n      <td>-0.531507</td>\n      <td>-1.008564</td>\n      <td>-0.947869</td>\n      <td>-0.664390</td>\n      <td>-0.409365</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>-0.704593</td>\n      <td>0.097075</td>\n      <td>-0.533676</td>\n      <td>-0.507531</td>\n      <td>-0.097829</td>\n      <td>-1.716827</td>\n      <td>-1.755353</td>\n      <td>-0.340049</td>\n      <td>-1.113178</td>\n      <td>-0.382990</td>\n      <td>-0.441483</td>\n      <td>-0.384283</td>\n      <td>0.392090</td>\n      <td>-0.222195</td>\n      <td>2.283511</td>\n      <td>0.601296</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>417</th>\n      <td>-0.625312</td>\n      <td>-0.548998</td>\n      <td>-0.393653</td>\n      <td>-0.890804</td>\n      <td>-0.890359</td>\n      <td>-0.374639</td>\n      <td>-1.877524</td>\n      <td>-1.107033</td>\n      <td>-0.798939</td>\n      <td>-0.824048</td>\n      <td>-0.826394</td>\n      <td>-0.825700</td>\n      <td>-0.704042</td>\n      <td>-0.832161</td>\n      <td>-1.224591</td>\n      <td>-0.942376</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>493</th>\n      <td>1.407756</td>\n      <td>-1.002750</td>\n      <td>1.634275</td>\n      <td>0.381003</td>\n      <td>0.177336</td>\n      <td>0.882659</td>\n      <td>1.772208</td>\n      <td>2.727886</td>\n      <td>0.950798</td>\n      <td>-0.727155</td>\n      <td>-0.778790</td>\n      <td>-0.864582</td>\n      <td>0.129387</td>\n      <td>-0.414433</td>\n      <td>0.861440</td>\n      <td>1.890209</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>177</th>\n      <td>-0.813878</td>\n      <td>3.291659</td>\n      <td>-1.310116</td>\n      <td>3.360619</td>\n      <td>2.969722</td>\n      <td>2.764531</td>\n      <td>0.978601</td>\n      <td>0.426934</td>\n      <td>2.042504</td>\n      <td>2.269002</td>\n      <td>2.231730</td>\n      <td>2.679046</td>\n      <td>3.030261</td>\n      <td>3.072342</td>\n      <td>0.278871</td>\n      <td>1.060516</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>112</th>\n      <td>-0.026166</td>\n      <td>0.972536</td>\n      <td>-0.625767</td>\n      <td>-0.205537</td>\n      <td>0.219807</td>\n      <td>-1.652657</td>\n      <td>-0.571046</td>\n      <td>-1.107033</td>\n      <td>-0.859580</td>\n      <td>1.577855</td>\n      <td>2.007490</td>\n      <td>1.362873</td>\n      <td>0.801238</td>\n      <td>1.849816</td>\n      <td>0.417637</td>\n      <td>-0.246091</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>-0.716752</td>\n      <td>2.830277</td>\n      <td>-1.207039</td>\n      <td>2.320741</td>\n      <td>2.284990</td>\n      <td>1.048269</td>\n      <td>1.315469</td>\n      <td>0.426934</td>\n      <td>1.625157</td>\n      <td>2.138479</td>\n      <td>2.075666</td>\n      <td>2.650899</td>\n      <td>1.916798</td>\n      <td>2.410884</td>\n      <td>0.046822</td>\n      <td>0.869918</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>220</th>\n      <td>-0.656152</td>\n      <td>-0.004056</td>\n      <td>-0.456864</td>\n      <td>-0.971758</td>\n      <td>-1.054307</td>\n      <td>-0.103754</td>\n      <td>-0.836701</td>\n      <td>-0.340049</td>\n      <td>-0.495085</td>\n      <td>-0.715596</td>\n      <td>-0.553193</td>\n      <td>-0.437514</td>\n      <td>-0.795005</td>\n      <td>-0.175838</td>\n      <td>-1.247266</td>\n      <td>-1.362879</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>381</th>\n      <td>-0.951318</td>\n      <td>-0.435371</td>\n      <td>-0.421375</td>\n      <td>-0.589330</td>\n      <td>-0.625773</td>\n      <td>-0.118633</td>\n      <td>-0.674102</td>\n      <td>-0.340049</td>\n      <td>-0.416496</td>\n      <td>-0.788625</td>\n      <td>-0.794964</td>\n      <td>-0.531353</td>\n      <td>-1.019610</td>\n      <td>-0.947760</td>\n      <td>-1.240359</td>\n      <td>-0.890810</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>460 rows × 17 columns</p>\n</div>"
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.concat([X_train, y_train], axis=1)\n",
    "data_cv = pd.concat([X_cv, y_cv], axis=1)\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "import torch\n",
    "\n",
    "X_train_ndarray = X_train.values\n",
    "y_train_ndarray = y_train.values\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(X_train_ndarray).type(torch.FloatTensor), torch.from_numpy(y_train_ndarray).type(torch.LongTensor))\n",
    "\n",
    "# for X_train_temp, y_train_temp in train_dataset:\n",
    "#     print(X_train_temp, y_train_temp)\n",
    "#     print(X_train_temp.dtype, y_train_temp.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_cv_ndarray = X_cv.values\n",
    "y_cv_ndarray = y_cv.values\n",
    "\n",
    "cv_dataset = TensorDataset(torch.from_numpy(X_cv_ndarray).type(torch.FloatTensor), torch.from_numpy(y_cv.values).type(torch.LongTensor))\n",
    "\n",
    "# for X_cv_temp, y_cv_temp in cv_dataset:\n",
    "#     print(X_cv_temp, y_cv_temp)\n",
    "#     print(X_cv_temp.dtype, y_cv_temp.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=para.batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "cv_dataloader = DataLoader(\n",
    "    dataset=cv_dataset,\n",
    "    batch_size=para.batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 构建测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data_test = None\n",
    "# for i_month in para.month_test:\n",
    "#\n",
    "#     file_name = para.data_path + '/' + str(i_month) + '.csv'\n",
    "#     data_curr_month = pd.read_csv(file_name)\n",
    "#\n",
    "#     data_curr_month = data_curr_month.dropna(axis=0)\n",
    "#\n",
    "#     data_curr_month = label_data(data=data_curr_month, percent_select=para.percent_select)\n",
    "#\n",
    "#     if i_month == para.month_test[0]:\n",
    "#         data_test = data_curr_month\n",
    "#     else:\n",
    "#         data_test = pd.concat([data_test, data_curr_month])\n",
    "#         # data_test = data_test.append(data_curr_month)\n",
    "#\n",
    "# X_test = data_test.loc[:, para.feature_column_start_name: para.feature_column_end_name]\n",
    "# y_test = data_test.loc[:, 'return_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import TensorDataset\n",
    "# import torch\n",
    "#\n",
    "#\n",
    "# X_test_ndarray = X_test.values\n",
    "# y_test_ndarray = y_test.values\n",
    "#\n",
    "# test_dataset = TensorDataset(torch.from_numpy(X_test_ndarray).type(torch.FloatTensor), torch.from_numpy(y_test_ndarray).type(torch.LongTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "#\n",
    "#\n",
    "# test_dataloader = DataLoader(\n",
    "#     dataset=test_dataset,\n",
    "#     batch_size=para.batch_size,\n",
    "#     shuffle=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 构建神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear_stack): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (1): Dropout(p=0.5, inplace=False)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=8, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from my_utils.model_class import MLP\n",
    "\n",
    "model = MLP(in_nums=len(X_train.columns), out_nums=para.classification, drop_p=para.drop)\n",
    "# to device\n",
    "model = model.to(device=para.device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 训练与测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss, correct = 0, 0\n",
    "\n",
    "    # initialize metric\n",
    "    train_precision = torchmetrics.Precision(average='none', num_classes=para.classification).to(device=para.device)\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "        # to device\n",
    "        X = X.to(device=para.device)\n",
    "        y = y.to(device=para.device)\n",
    "\n",
    "        # compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        train_loss += loss_fn(pred, y).item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        # metric on current batch\n",
    "        train_precision(pred.argmax(1), y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if batch % 10 == 0:\n",
    "        #     loss, current = loss.item(), batch * len(X)\n",
    "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    train_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Train Error: \\n    Accuracy: {(100*correct):>0.1f}%, Avg loss: {train_loss:>8f} \\n\")\n",
    "\n",
    "    # metric on all batches using custom accumulation\n",
    "    total_precision = train_precision.compute()\n",
    "    print(\"Precision of every train dataset class: \", total_precision)\n",
    "    print()\n",
    "\n",
    "    return correct, train_loss, total_precision\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # initialize metric\n",
    "    test_precision = torchmetrics.Precision(average='none', num_classes=para.classification).to(device=para.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "\n",
    "            # to device\n",
    "            X = X.to(device=para.device)\n",
    "            y = y.to(device=para.device)\n",
    "\n",
    "            # compute prediction and loss\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "            # metric on current batch\n",
    "            test_precision(pred.argmax(1), y)\n",
    "\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n    Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    # metric on all batches using custom accumulation\n",
    "    total_precision = test_precision.compute()\n",
    "    print(\"Precision of every test dataset class: \", total_precision)\n",
    "    print()\n",
    "\n",
    "    return correct, test_loss, total_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def select_df_to_dataloader(df: pd.DataFrame, select: int) -> DataLoader:\n",
    "\n",
    "    df = df[df['return_bin'] == select]\n",
    "\n",
    "    df_dataset = TensorDataset(\n",
    "        torch.from_numpy(df.loc[:, para.feature_column_start_name: para.feature_column_end_name].values).type(torch.FloatTensor),\n",
    "        torch.from_numpy(df.loc[:, 'return_bin'].values).type(torch.LongTensor))\n",
    "\n",
    "    df_dataloader = DataLoader(\n",
    "        dataset=df_dataset,\n",
    "        batch_size=para.batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    return df_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# temp2_dataloader = select_df_to_dataloader(df=data_cv, select=2)\n",
    "temp1_dataloader = select_df_to_dataloader(df=data_cv, select=1)\n",
    "temp0_dataloader = select_df_to_dataloader(df=data_cv, select=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 53.7%, Avg loss: 0.689716 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.3907, 0.6084], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.9%, Avg loss: 0.685483 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.3750, 0.5455], device='cuda:0')\n",
      "\n",
      "Time cost = 0.343082s\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 59.1%, Avg loss: 0.678976 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.4474, 0.6198], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 53.8%, Avg loss: 0.673531 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4000, 0.5532], device='cuda:0')\n",
      "\n",
      "Time cost = 0.709515s\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 64.1%, Avg loss: 0.664971 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6119, 0.6463], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.9%, Avg loss: 0.672375 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.2500, 0.5417], device='cuda:0')\n",
      "\n",
      "Time cost = 1.027090s\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 65.2%, Avg loss: 0.639034 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7083, 0.6456], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 53.8%, Avg loss: 0.661367 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4000, 0.5532], device='cuda:0')\n",
      "\n",
      "Time cost = 1.362464s\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 65.7%, Avg loss: 0.629679 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6774, 0.6533], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 51.9%, Avg loss: 0.643160 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.3333, 0.5435], device='cuda:0')\n",
      "\n",
      "Time cost = 1.720162s\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 65.0%, Avg loss: 0.627823 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6338, 0.6530], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 53.8%, Avg loss: 0.597838 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.4286, 0.5556], device='cuda:0')\n",
      "\n",
      "Time cost = 2.075077s\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 66.1%, Avg loss: 0.600417 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6538, 0.6623], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 65.4%, Avg loss: 0.596938 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.6923, 0.6410], device='cuda:0')\n",
      "\n",
      "Time cost = 2.438106s\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 69.8%, Avg loss: 0.584830 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7030, 0.6964], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 67.3%, Avg loss: 0.636492 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.6875, 0.6667], device='cuda:0')\n",
      "\n",
      "Time cost = 2.783601s\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 75.7%, Avg loss: 0.557359 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7537, 0.7577], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 75.0%, Avg loss: 0.573747 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7500, 0.7500], device='cuda:0')\n",
      "\n",
      "Time cost = 3.112143s\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 70.9%, Avg loss: 0.555474 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7018, 0.7110], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 75.0%, Avg loss: 0.599883 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7083, 0.7857], device='cuda:0')\n",
      "\n",
      "Time cost = 3.417929s\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 75.0%, Avg loss: 0.536131 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7372, 0.7554], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 75.0%, Avg loss: 0.671150 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7083, 0.7857], device='cuda:0')\n",
      "\n",
      "Time cost = 3.703494s\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 74.1%, Avg loss: 0.523396 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7163, 0.7524], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 75.0%, Avg loss: 0.624254 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7083, 0.7857], device='cuda:0')\n",
      "\n",
      "Time cost = 4.027708s\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 75.4%, Avg loss: 0.519996 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7410, 0.7601], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 75.0%, Avg loss: 0.504714 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7083, 0.7857], device='cuda:0')\n",
      "\n",
      "Time cost = 4.345554s\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 77.4%, Avg loss: 0.487938 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7533, 0.7839], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 75.0%, Avg loss: 0.514806 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7083, 0.7857], device='cuda:0')\n",
      "\n",
      "Time cost = 4.652301s\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 77.2%, Avg loss: 0.494225 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7358, 0.7907], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 75.0%, Avg loss: 0.580372 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7273, 0.7667], device='cuda:0')\n",
      "\n",
      "Time cost = 4.958289s\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 77.8%, Avg loss: 0.488509 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7437, 0.7967], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 75.0%, Avg loss: 0.586489 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7273, 0.7667], device='cuda:0')\n",
      "\n",
      "Time cost = 5.250514s\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 76.5%, Avg loss: 0.495798 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7169, 0.7925], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 75.0%, Avg loss: 0.484063 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7273, 0.7667], device='cuda:0')\n",
      "\n",
      "Time cost = 5.549752s\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 78.5%, Avg loss: 0.501858 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7425, 0.8089], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 75.0%, Avg loss: 0.574995 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7273, 0.7667], device='cuda:0')\n",
      "\n",
      "Time cost = 5.856885s\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 74.3%, Avg loss: 0.486809 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.6938, 0.7700], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 75.0%, Avg loss: 0.542287 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7273, 0.7667], device='cuda:0')\n",
      "\n",
      "Time cost = 6.127805s\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 78.3%, Avg loss: 0.466850 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7381, 0.8082], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 73.1%, Avg loss: 0.540755 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7143, 0.7419], device='cuda:0')\n",
      "\n",
      "Time cost = 6.429632s\n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 79.8%, Avg loss: 0.456880 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7669, 0.8148], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 73.1%, Avg loss: 0.490762 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7143, 0.7419], device='cuda:0')\n",
      "\n",
      "Time cost = 6.774109s\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 80.4%, Avg loss: 0.452703 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7744, 0.8209], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 73.1%, Avg loss: 0.581921 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7143, 0.7419], device='cuda:0')\n",
      "\n",
      "Time cost = 7.083755s\n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 79.6%, Avg loss: 0.455866 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7622, 0.8142], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 73.1%, Avg loss: 0.494917 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7143, 0.7419], device='cuda:0')\n",
      "\n",
      "Time cost = 7.560111s\n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 79.8%, Avg loss: 0.469634 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7771, 0.8086], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 75.0%, Avg loss: 0.526384 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7273, 0.7667], device='cuda:0')\n",
      "\n",
      "Time cost = 7.948073s\n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 79.3%, Avg loss: 0.418072 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7778, 0.8013], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 75.0%, Avg loss: 0.470748 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7500, 0.7500], device='cuda:0')\n",
      "\n",
      "Time cost = 8.270319s\n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 78.5%, Avg loss: 0.446312 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7547, 0.8007], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 73.1%, Avg loss: 0.500897 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7143, 0.7419], device='cuda:0')\n",
      "\n",
      "Time cost = 8.570519s\n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 80.0%, Avg loss: 0.429219 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7619, 0.8219], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 75.0%, Avg loss: 0.567328 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7500, 0.7500], device='cuda:0')\n",
      "\n",
      "Time cost = 8.861748s\n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 77.6%, Avg loss: 0.476633 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7391, 0.7960], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 76.9%, Avg loss: 0.616572 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7619, 0.7742], device='cuda:0')\n",
      "\n",
      "Time cost = 9.158838s\n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 77.2%, Avg loss: 0.444663 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7301, 0.7946], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 76.9%, Avg loss: 0.478117 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7895, 0.7576], device='cuda:0')\n",
      "\n",
      "Time cost = 9.431666s\n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 81.7%, Avg loss: 0.439652 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7892, 0.8333], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 76.9%, Avg loss: 0.556322 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7895, 0.7576], device='cuda:0')\n",
      "\n",
      "Time cost = 9.711001s\n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 82.2%, Avg loss: 0.407423 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7882, 0.8414], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 75.0%, Avg loss: 0.612965 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7500, 0.7500], device='cuda:0')\n",
      "\n",
      "Time cost = 10.051785s\n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 81.3%, Avg loss: 0.414616 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7701, 0.8392], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 76.9%, Avg loss: 0.551367 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7619, 0.7742], device='cuda:0')\n",
      "\n",
      "Time cost = 10.354295s\n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 80.4%, Avg loss: 0.415317 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7744, 0.8209], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 78.8%, Avg loss: 0.538742 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8000, 0.7812], device='cuda:0')\n",
      "\n",
      "Time cost = 10.648544s\n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 81.3%, Avg loss: 0.427927 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7866, 0.8277], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 76.9%, Avg loss: 0.606969 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7895, 0.7576], device='cuda:0')\n",
      "\n",
      "Time cost = 10.937484s\n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 80.2%, Avg loss: 0.463232 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7799, 0.8140], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 78.8%, Avg loss: 0.471557 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8000, 0.7812], device='cuda:0')\n",
      "\n",
      "Time cost = 11.205614s\n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 83.5%, Avg loss: 0.395211 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8171, 0.8446], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 78.8%, Avg loss: 0.474695 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8000, 0.7812], device='cuda:0')\n",
      "\n",
      "Time cost = 11.582980s\n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 80.0%, Avg loss: 0.415187 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7619, 0.8219], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 78.8%, Avg loss: 0.578799 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8000, 0.7812], device='cuda:0')\n",
      "\n",
      "Time cost = 11.937032s\n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 84.8%, Avg loss: 0.410882 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8438, 0.8500], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 78.8%, Avg loss: 0.623966 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8000, 0.7812], device='cuda:0')\n",
      "\n",
      "Time cost = 12.287981s\n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 81.7%, Avg loss: 0.384074 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7824, 0.8379], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 76.9%, Avg loss: 0.489191 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7619, 0.7742], device='cuda:0')\n",
      "\n",
      "Time cost = 12.667964s\n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 83.5%, Avg loss: 0.419247 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7955, 0.8592], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 76.9%, Avg loss: 0.551113 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7619, 0.7742], device='cuda:0')\n",
      "\n",
      "Time cost = 13.051940s\n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 83.5%, Avg loss: 0.406745 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8333, 0.8355], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.446980 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 13.390996s\n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 81.1%, Avg loss: 0.431664 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8079, 0.8123], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.477329 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 13.704160s\n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 82.2%, Avg loss: 0.396520 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8062, 0.8300], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.471387 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 14.004854s\n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 79.3%, Avg loss: 0.391056 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7778, 0.8013], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 76.9%, Avg loss: 0.487611 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.7619, 0.7742], device='cuda:0')\n",
      "\n",
      "Time cost = 14.311059s\n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 85.0%, Avg loss: 0.435400 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8208, 0.8676], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.637149 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 14.615247s\n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 82.6%, Avg loss: 0.393127 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.7941, 0.8448], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.436189 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 14.889942s\n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 81.7%, Avg loss: 0.411799 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8158, 0.8182], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.485837 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 15.159046s\n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 82.6%, Avg loss: 0.385574 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8125, 0.8333], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.486963 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 15.431962s\n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 82.6%, Avg loss: 0.442758 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8086, 0.8356], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.456564 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 15.816933s\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 82.6%, Avg loss: 0.416432 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8205, 0.8289], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.435848 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 16.172980s\n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 82.8%, Avg loss: 0.403084 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8258, 0.8295], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.549458 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 16.503591s\n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 80.7%, Avg loss: 0.434649 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8054, 0.8071], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.539634 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 16.814484s\n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 84.1%, Avg loss: 0.395149 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8543, 0.8350], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.433170 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 17.118440s\n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 82.2%, Avg loss: 0.360291 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8101, 0.8278], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.552184 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 17.393130s\n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 85.2%, Avg loss: 0.413873 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8333, 0.8630], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.563656 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 17.717236s\n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 82.0%, Avg loss: 0.398373 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8170, 0.8208], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.470363 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 18.009081s\n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 83.0%, Avg loss: 0.406867 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8269, 0.8322], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.450542 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 18.285465s\n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 83.7%, Avg loss: 0.371247 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8431, 0.8339], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.548488 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 18.547423s\n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 85.4%, Avg loss: 0.376124 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8424, 0.8610], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 78.8%, Avg loss: 0.436325 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8000, 0.7812], device='cuda:0')\n",
      "\n",
      "Time cost = 18.828640s\n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 83.0%, Avg loss: 0.394572 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8188, 0.8367], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.570288 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 19.109643s\n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 81.7%, Avg loss: 0.405900 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8200, 0.8161], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.432273 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 19.386567s\n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 82.2%, Avg loss: 0.383232 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8141, 0.8257], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.510473 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 19.680316s\n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 83.0%, Avg loss: 0.377773 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8400, 0.8258], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.541523 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 19.954977s\n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 85.2%, Avg loss: 0.371312 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8636, 0.8464], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.702591 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 20.247883s\n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 82.0%, Avg loss: 0.400436 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8345, 0.8127], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.582574 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 20.528996s\n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 83.5%, Avg loss: 0.405003 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8291, 0.8377], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.539455 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 20.843941s\n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 82.6%, Avg loss: 0.368448 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8165, 0.8311], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.422615 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 21.134239s\n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 86.3%, Avg loss: 0.339878 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8726, 0.8581], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.416271 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 21.410259s\n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 83.3%, Avg loss: 0.410223 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8323, 0.8328], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.447299 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 21.687844s\n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 84.3%, Avg loss: 0.382708 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8462, 0.8421], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.464974 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 21.958315s\n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 85.7%, Avg loss: 0.378508 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8608, 0.8543], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.420390 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 22.261497s\n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 83.5%, Avg loss: 0.399911 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8291, 0.8377], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.550886 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 22.597599s\n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 84.3%, Avg loss: 0.387721 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8253, 0.8537], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.599253 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 22.937558s\n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 82.6%, Avg loss: 0.348886 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8125, 0.8333], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.443523 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 23.245455s\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 83.0%, Avg loss: 0.357765 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8188, 0.8367], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.422334 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 23.594523s\n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 84.1%, Avg loss: 0.366403 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8323, 0.8462], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.425450 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 24.011209s\n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 83.7%, Avg loss: 0.384420 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8431, 0.8339], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.434773 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 24.481951s\n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 82.0%, Avg loss: 0.396727 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8170, 0.8208], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.449870 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 24.981614s\n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 82.0%, Avg loss: 0.374447 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8440, 0.8088], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.510616 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 25.382976s\n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 83.5%, Avg loss: 0.357074 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8250, 0.8400], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.500436 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 25.765377s\n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 83.5%, Avg loss: 0.376044 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8291, 0.8377], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.398054 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 26.087517s\n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 86.3%, Avg loss: 0.349848 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8634, 0.8629], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.461541 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 26.413774s\n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 83.7%, Avg loss: 0.375830 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8431, 0.8339], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.485460 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 26.766920s\n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 84.6%, Avg loss: 0.344550 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8344, 0.8519], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.397440 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 27.101564s\n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 84.3%, Avg loss: 0.369970 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8600, 0.8355], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.516261 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 27.427289s\n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 85.2%, Avg loss: 0.357997 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8636, 0.8464], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.425828 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 27.775632s\n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 83.0%, Avg loss: 0.373323 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8400, 0.8258], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.566547 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 28.075404s\n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 85.2%, Avg loss: 0.357097 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8684, 0.8442], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.424765 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 28.421544s\n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 86.7%, Avg loss: 0.326258 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8742, 0.8638], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.498904 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 28.737916s\n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 84.1%, Avg loss: 0.355883 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8497, 0.8371], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.632437 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 29.044430s\n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 83.5%, Avg loss: 0.396883 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8250, 0.8400], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.405270 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 29.359577s\n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 85.7%, Avg loss: 0.340274 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8519, 0.8591], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.525204 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 29.690165s\n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 83.5%, Avg loss: 0.354795 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8377, 0.8333], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.414005 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 30.017668s\n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 86.5%, Avg loss: 0.304039 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8831, 0.8562], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.429975 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 30.339082s\n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 85.2%, Avg loss: 0.348011 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8636, 0.8464], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.522209 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 30.685520s\n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 85.7%, Avg loss: 0.321948 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8434, 0.8639], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.551058 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 31.020305s\n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 85.7%, Avg loss: 0.360343 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8750, 0.8474], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.564904 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 31.303016s\n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 85.7%, Avg loss: 0.324879 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8750, 0.8474], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.435551 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 31.593419s\n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 85.0%, Avg loss: 0.350003 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8447, 0.8528], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 80.8%, Avg loss: 0.476939 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8421, 0.7879], device='cuda:0')\n",
      "\n",
      "Time cost = 31.916990s\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train Error: \n",
      "    Accuracy: 84.6%, Avg loss: 0.331339 \n",
      "\n",
      "Precision of every train dataset class:  tensor([0.8428, 0.8472], device='cuda:0')\n",
      "\n",
      "Test Error: \n",
      "    Accuracy: 82.7%, Avg loss: 0.485956 \n",
      "\n",
      "Precision of every test dataset class:  tensor([0.8889, 0.7941], device='cuda:0')\n",
      "\n",
      "Time cost = 32.242558s\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 计时\n",
    "time_start = time.time()\n",
    "\n",
    "# writer = SummaryWriter(para.tensor_board_log_dir)\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# to device\n",
    "loss_fn = loss_fn.to(device=para.device)\n",
    "\n",
    "# 优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=para.lr)\n",
    "\n",
    "epochs = para.epochs\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "\n",
    "    model.train()\n",
    "    accuracy_train, loss_train, precision_train = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    model.eval()\n",
    "    accuracy_cv, loss_cv, precision_cv = test_loop(cv_dataloader, model, loss_fn)\n",
    "\n",
    "    # accuracy2 = test_loop(temp2_dataloader, model, loss_fn)\n",
    "    # print('#')\n",
    "    # accuracy1 = test_loop(temp1_dataloader, model, loss_fn)\n",
    "    # accuracy0 = test_loop(temp0_dataloader, model, loss_fn)\n",
    "\n",
    "    # 写入 tensorboard\n",
    "    if para.classification == 2:\n",
    "\n",
    "        writer.add_scalars(main_tag=para.info_str+'_evaluation/cv',\n",
    "                           tag_scalar_dict={\n",
    "                               'accuracy': accuracy_cv,\n",
    "                               'precision0': precision_cv[0],\n",
    "                               'precision1': precision_cv[1]},\n",
    "                           global_step=t)\n",
    "\n",
    "        writer.add_scalars(main_tag=para.info_str+'_evaluation/train',\n",
    "                           tag_scalar_dict={\n",
    "                               'accuracy': accuracy_train,\n",
    "                               'precision0': precision_train[0],\n",
    "                               'precision1': precision_train[1]},\n",
    "                           global_step=t)\n",
    "\n",
    "    elif para.classification == 3:\n",
    "\n",
    "        writer.add_scalars(main_tag=para.info_str+'_evaluation/cv',\n",
    "                           tag_scalar_dict={\n",
    "                               'accuracy': accuracy_cv,\n",
    "                               'precision0': precision_cv[0],\n",
    "                               'precision1': precision_cv[1],\n",
    "                               'precision2': precision_cv[2]},\n",
    "                           global_step=t)\n",
    "\n",
    "        writer.add_scalars(main_tag=para.info_str+'_evaluation/train',\n",
    "                           tag_scalar_dict={\n",
    "                               'accuracy': accuracy_train,\n",
    "                               'precision0': precision_train[0],\n",
    "                               'precision1': precision_train[1],\n",
    "                               'precision2': precision_train[2]},\n",
    "                           global_step=t)\n",
    "\n",
    "    elif para.classification == 5:\n",
    "\n",
    "        writer.add_scalars(main_tag=para.info_str+'_evaluation/cv',\n",
    "                           tag_scalar_dict={\n",
    "                               'accuracy': accuracy_cv,\n",
    "                               'precision0': precision_cv[0],\n",
    "                               'precision1': precision_cv[1],\n",
    "                               'precision2': precision_cv[2],\n",
    "                               'precision3': precision_cv[3],\n",
    "                               'precision4': precision_cv[4]},\n",
    "                           global_step=t)\n",
    "\n",
    "        writer.add_scalars(main_tag=para.info_str+'_evaluation/train',\n",
    "                           tag_scalar_dict={\n",
    "                               'accuracy': accuracy_train,\n",
    "                               'precision0': precision_train[0],\n",
    "                               'precision1': precision_train[1],\n",
    "                               'precision2': precision_train[2],\n",
    "                               'precision3': precision_train[3],\n",
    "                               'precision4': precision_train[4]},\n",
    "                           global_step=t)\n",
    "\n",
    "    writer.add_scalars(main_tag=para.info_str+'_loss/cv',\n",
    "                       tag_scalar_dict={\n",
    "                           'loss': loss_cv},\n",
    "                       global_step=t)\n",
    "\n",
    "    writer.add_scalars(main_tag=para.info_str+'_loss/train',\n",
    "                       tag_scalar_dict={\n",
    "                           'loss': loss_train},\n",
    "                       global_step=t)\n",
    "    writer.flush()\n",
    "\n",
    "    time_end = time.time()\n",
    "    print('Time cost = %fs' % (time_end - time_start))\n",
    "    print()\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 保存模型"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish save model!\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), para.save_model_path)\n",
    "\n",
    "print('Finish save model!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # captum\n",
    "# from captum.attr import IntegratedGradients\n",
    "#\n",
    "# ig = IntegratedGradients(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# temp = cv_dataloader.dataset.tensors[0]\n",
    "# temp.requires_grad_()\n",
    "# attr, delta = ig.attribute(temp,target=1, return_convergence_delta=True)\n",
    "# attr = attr.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Helper method to print importances and visualize distribution\n",
    "# def visualize_importances(feature_names, importances, title=\"Average Feature Importances\", plot=True, axis_title=\"Features\"):\n",
    "#     print(title)\n",
    "#     for i in range(len(feature_names)):\n",
    "#         print(feature_names[i], \": \", '%.3f'%(importances[i]))\n",
    "#     y_pos = (np.arange(len(feature_names)))\n",
    "#     if plot:\n",
    "#         plt.figure(figsize=(20,6))\n",
    "#         plt.barh(y_pos, importances, align='center')\n",
    "#         plt.yticks(y_pos, feature_names)\n",
    "#         plt.ylabel(axis_title)\n",
    "#         plt.grid(axis='y')\n",
    "#         plt.title(title)\n",
    "# visualize_importances(feature_names=X_cv.columns.values.tolist(), importances=np.mean(attr, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# X_cv.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# loss = nn.CrossEntropyLoss()\n",
    "# input = torch.Tensor(\n",
    "#     [[-0.0441,  0.0773],\n",
    "#     [-0.0781, -0.1772],\n",
    "#     [-0.1319, -0.0432],\n",
    "#     [-0.0714, -0.1261],\n",
    "#     [-0.0806, -0.1370],\n",
    "#     [-0.1730, -0.1472],\n",
    "#     [-0.0350, -0.0507],\n",
    "#     [-0.1149, -0.2248]])\n",
    "# # input = input.reshape(-1,4)\n",
    "# target = torch.Tensor([0, 1, 1, 0, 0, 0, 0, 0]).type(torch.LongTensor)\n",
    "# print(input.dtype)\n",
    "# print(target.dtype)\n",
    "# output = loss(input, target)\n",
    "# print(input, target, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Example of target with class indices\n",
    "# loss = nn.CrossEntropyLoss()\n",
    "# input = torch.randn(3, 5, requires_grad=True)\n",
    "# target = torch.Tensor([1,4,1]).type(torch.LongTensor)\n",
    "# output = loss(input, target)\n",
    "# print(input,target,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# loss = nn.BCEWithLogitsLoss()\n",
    "# input = torch.Tensor([0.5, 0.4, 0.3])\n",
    "# target = torch.Tensor([0])\n",
    "# output = loss(input, target)\n",
    "# print(input, target, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}